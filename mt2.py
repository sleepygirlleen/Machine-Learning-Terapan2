# -*- coding: utf-8 -*-
"""MT2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vLzXn_mZdk8xvxmWG5TOqthi4-GlwHUj

#**Proyek Machine Learning Terapan 2**

- **Nama:** Sulistiani
- **Email:** lisasa2lilisa@gmail.com
- **ID Dicoding:** hi_itslizeu

## **Import Library**
"""

from sklearn.svm import SVR
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import pandas as pd
import numpy as np
from sklearn import metrics
import matplotlib.pyplot as plt
from sklearn.neighbors import NearestNeighbors
import seaborn as sns

"""## **Import Dataset**"""

df = pd.read_csv('manga.csv')

"""## **Assessing Data**"""

df.shape

df.head()

df.info()

"""## **Checking Missing Values**"""

df.isnull().sum()

df.duplicated().any()

"""## **Data Preparation**

### **Cleaning Data**

#### **Menghapus Kolom**
"""

df.drop(columns=['Themes',	'Demographics',	'Serialization', 'Members',	'Favorite'], inplace=True)

"""#### **Membersihkan Data Kosong**"""

df = df[df['Genres'].str.strip() != '[]']

"""#### **IQR**"""

numeric_features = df.select_dtypes(include=np.number).columns.tolist()

for feature in numeric_features:
    plt.figure(figsize=(10, 6))
    sns.boxplot(x=df[feature])
    plt.title(f'Box Plot of {feature}')
    plt.show()

Q1 = df[numeric_features].quantile(0.25)
Q3 = df[numeric_features].quantile(0.75)
IQR = Q3 - Q1

# Filter dataframe untuk hanya menyimpan baris yang tidak mengandung outliers pada kolom numerik
condition = ~((df[numeric_features] < (Q1 - 1.5 * IQR)) | (df[numeric_features] > (Q3 + 1.5 * IQR))).any(axis=1)
df_filtered_numeric = df.loc[condition, numeric_features]

# Menggabungkan kembali dengan kolom kategorikal
categorical_features = df.select_dtypes(include=['object']).columns
df = pd.concat([df_filtered_numeric, df.loc[condition, categorical_features]], axis=1)

"""### **Data Transformation**

#### **Encoding**
"""

df['Genres'] = df['Genres'].astype(str)

df['Genres_list'] = df['Genres'].str.split(',')

genres_encoded = df['Genres_list'].str.join('|').str.get_dummies()

"""#### **Feature Engineering**"""

feature_cols = df.drop(['Title','Genres'], axis=1)
X = feature_cols

"""#### **Handling Missing Value**"""

for col in X.columns:
    if X[col].dtype == 'object':
        X[col] = X[col].replace(['Unknown', '-', 'Not available'], np.nan)
        X[col] = pd.to_numeric(X[col], errors='coerce')

"""#### **Feature Selection**"""

for col in X.columns:
    if pd.api.types.is_numeric_dtype(X[col]):
         if X[col].isnull().any():
            median_val = X[col].median()
            if not np.isnan(median_val):
                X[col] = X[col].fillna(median_val)
            else:
                X[col] = X[col].fillna(0)


if X.isnull().sum().sum() > 0:
    print("Warning: There are still NaN values in the DataFrame after cleaning.")
    print(X.isnull().sum()[X.isnull().sum() > 0])

X_with_genres = pd.concat([X, genres_encoded], axis=1)

X_final = X.copy()

# Tambahkan fitur genre yang di-encode
X_final = pd.concat([X_final, genres_encoded], axis=1)


# Tambahkan fitur Status (jika kategorikal, lakukan one-hot encoding)
if 'Status' in df.columns:
    status_encoded = pd.get_dummies(df['Status'], prefix='Status')
    X_final = pd.concat([X_final, status_encoded], axis=1)
else:
     print("Warning: 'Status' column not found in df.")


if 'Published' in df.columns:
    try:
        df['Published_Year'] = pd.to_datetime(df['Published'], errors='coerce').dt.year
        published_numeric = df['Published_Year'].fillna(df['Published_Year'].median())
        X_final['Published_Year'] = published_numeric
    except:
        if pd.api.types.is_numeric_dtype(df['Published']):
             X_final['Published'] = df['Published']
        else:
             print("Warning: Could not process 'Published' column. It's not numeric and date conversion failed.")
else:
     print("Warning: 'Published' column not found in df.")

# Tambahkan fitur Score
if 'Score' in df.columns and pd.api.types.is_numeric_dtype(df['Score']):
     X_final['Score'] = df['Score']
elif 'Score' in df.columns:
     print("Warning: 'Score' column is not numeric. Please check cleaning steps.")
else:
     print("Warning: 'Score' column not found in df.")


# Pastikan tidak ada kolom non-numerik di X_final sebelum melatih model
X_final = X_final.select_dtypes(include=np.number)
X_final = X_final.dropna()

print(f"Shape of X_final: {X_final.shape}")
print("Columns in X_final:", X_final.columns.tolist())

"""## **Exploratory Data Analyst**

### **Score (Rating)**
"""

score = df.groupby("Score").agg({"Score":"count"})
df.sort_values(by="Score",ascending=False ).reset_index(drop=True).head()

# Mengurutkan dataframe berdasarkan Score tertinggi dan mengambil 10 teratas
top_scores = df[['Title', 'Score']].dropna().sort_values(by='Score', ascending=False).head(10)

# Visualisasi
plt.figure(figsize=(12, 8))  # Ukuran figure ditingkatkan untuk kejelasan

# Membuat bar chart horizontal
bars = plt.barh(top_scores['Title'], top_scores['Score'], color='#4aa3df')

# Judul dan label sumbu
plt.title('Top 10 Manga dengan Skor Tertinggi', fontsize=16, weight='bold')
plt.xlabel('Skor', fontsize=13)
plt.ylabel('Judul Manga', fontsize=13)
plt.xticks(fontsize=11)
plt.yticks(fontsize=11)

# Membalik sumbu Y agar skor tertinggi di atas
plt.gca().invert_yaxis()

# Menambahkan label skor di ujung bar
for bar in bars:
    width = bar.get_width()
    plt.text(width + 0.01, bar.get_y() + bar.get_height() / 2,
             f'{width:.2f}', va='center', fontsize=10, color='black')

# Fokus pada range skor yang sesuai jika semua mendekati angka tinggi
min_score = top_scores['Score'].min() - 0.02
max_score = top_scores['Score'].max() + 0.02
plt.xlim(min_score, max_score)

# Memberi grid ringan pada sumbu X
plt.grid(axis='x', linestyle='--', alpha=0.6)

plt.tight_layout()
plt.show()

"""### **Published**"""

published = df.groupby("Published").agg({"Published":"min"})
df.sort_values(by="Published", ascending=True).reset_index(drop=True).head()

df['Year'] = pd.to_datetime(df['Published'], errors='coerce').dt.year

counts_per_year = df.groupby('Year').size().reset_index(name='Count')

plt.figure(figsize=(12,6))
plt.bar(counts_per_year['Year'], counts_per_year['Count'], color='skyblue')
plt.xlabel('Year')
plt.ylabel('Number of Manga Published')
plt.title('Number of Manga Published Per Year')
plt.xticks(rotation=45)
plt.show()

"""### **Status**"""

Status = df.groupby("Status").agg({"Status":"count"})

figsize = (15,5)
fig, (ax1, ax2) = plt.subplots(1,2,figsize=figsize)
Status.plot.pie(ax=ax1,y="Status", legend=False, autopct='%1.f%%', startangle=90, fontsize="x-large")
ax1.set_ylabel('')
Status.plot.bar(ax=ax2,  fontsize="large")

plt.show()

"""### **Genre**"""

# Melihat Top Genre Terbanyak
all_genres = [genre.strip() for genres_list in df['Genres_list'].dropna() for genre in genres_list]

genre_counts = pd.Series(all_genres).value_counts()

# Menampilkan 10 genre teratas
print("Top 10 Genre Terbanyak:")
print(genre_counts.head(10))

# Visualisasi Distribusi Genre (Top 10)
plt.figure(figsize=(15, 8))
genre_counts.head(10).plot(kind='bar')
plt.title('Distribusi Top 10 Genre Manga')
plt.xlabel('Genre')
plt.ylabel('Jumlah Manga')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

"""## **Modelling**

#### **TFIDF**
"""

tfid = TfidfVectorizer()
tfid.fit(df['Genres'])

tfid.get_feature_names_out()

tfidf_matrix = tfid.fit_transform(df['Genres'])
tfidf_matrix.shape

tfidf_matrix.todense()

df_tfidf = pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tfid.get_feature_names_out(),
    index=df['Title']
)

df_tfidf.sample(10, axis=0).sample(22, axis=1)

"""#### **Consine Similiarity**"""

cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

cosine_sim_df = pd.DataFrame(
    cosine_sim,
    index=df['Title'],
    columns=df['Title']
)

print(f"Ukuran cosine_sim_df: {cosine_sim_df.shape[0]} baris x {cosine_sim_df.shape[1]} kolom")

sample_matrix = cosine_sim_df.sample(5, axis=1).sample(5, axis=0)
display(sample_matrix)

def manga_recommendations(manga_name, similarity_data=cosine_sim_df, items=df[['Title', 'Genres']], k=10):
    result = items[items['Title'].str.contains(manga_name, case=False, na=False)]

    if len(result) > 0:
        return result.head(k)

    if manga_name not in similarity_data.columns:
        return f"Anime '{manga_name}' tidak ditemukan dalam data similarity."

    similarity_scores = similarity_data[manga_name].to_numpy()
    top_indices = similarity_scores.argsort()[::-1]
    similar_names = [similarity_data.columns[idx] for idx in top_indices if similarity_data.columns[idx] != manga_name][:k]
    return pd.DataFrame({'Title': similar_names}).merge(items, on='Title', how='left')

manga_recommendations("One Piece")

"""#### **K-Nearest Neighbors**"""

manga_title_to_recommend = 'One Piece'

query_result = df[df['Title'].str.contains(manga_title_to_recommend, case=False, na=False)]

if not query_result.empty:
    # Ambil index pertama yang cocok
    manga_index = query_result.index[0]

    # Ambil vektor fiturnya dari X_final
    if X_final.isnull().sum().sum() > 0:
        print("Warning: X_final still contains NaN values.")

    manga_features = X_final.iloc[manga_index].values.reshape(1, -1)

    # Cari tetangga terdekat
    neigh = NearestNeighbors(n_neighbors=6, metric='cosine', algorithm='brute')
    # Fit the model with the data
    neigh.fit(X_final) # <-- Tambahkan baris ini

    distances, indices = neigh.kneighbors(manga_features)

    print(f'Recommendations for "{manga_title_to_recommend}":\n')

    # Mulai dari 1 karena 0 adalah dirinya sendiri
    for i in range(1, len(distances.flatten())):
        idx = indices.flatten()[i]
        distance = distances.flatten()[i]
        # Pastikan idx valid untuk df sebelum mengaksesnya
        if idx < len(df):
            recommended_title = df.iloc[idx]['Title']
            print(f'{i}: {recommended_title}, with a distance of {distance:.4f}')
        else:
            print(f"Warning: Index {idx} out of bounds for df.")

else:
    print(f"Manga '{manga_title_to_recommend}' not found in the dataset.")

"""## **Evaluation**"""

def precision_at_k(recommendations, ground_truth, k=5):
    if not recommendations or not ground_truth:
        return 0.0
    recommended_k = recommendations[:k]
    relevant = [item for item in recommended_k if item in ground_truth]
    return len(relevant) / k

def recall_at_k(recommendations, ground_truth, k=5):
    if not recommendations or not ground_truth:
        return 0.0
    recommended_k = recommendations[:k]
    relevant = [item for item in recommended_k if item in ground_truth]
    return len(relevant) / len(ground_truth)

# Data ground truth (item yang benar-benar disukai user)
ground_truth = [
    ['Naruto', 'One Piece', 'Bleach'],  # user 1
    ['Attack on Titan', 'Death Note'],  # user 2
    ['Demon Slayer', 'Jujutsu Kaisen'], # user 3
]

# Data rekomendasi dari CBF (harus kamu generate sendiri)
cbf_recommendations = [
    ['Naruto', 'Bleach', 'Dragon Ball', 'One Piece', 'Fairy Tail'],
    ['Death Note', 'Black Clover', 'Attack on Titan', 'Tokyo Ghoul', 'Code Geass'],
    ['Jujutsu Kaisen', 'Demon Slayer', 'Chainsaw Man', 'Blue Lock', 'My Hero Academia'],
]

# Data rekomendasi dari KNN (harus kamu generate sendiri)
knn_recommendations = [
    ['One Piece', 'Naruto', 'Bleach', 'Dragon Ball', 'Fairy Tail'],
    ['Attack on Titan', 'Death Note', 'Black Clover', 'Tokyo Ghoul', 'Code Geass'],
    ['Demon Slayer', 'Jujutsu Kaisen', 'My Hero Academia', 'Chainsaw Man', 'Blue Lock'],
]

# Hitung precision dan recall untuk CBF
precisions_cbf = [precision_at_k(rec, truth, k=5) for rec, truth in zip(cbf_recommendations, ground_truth)]
recalls_cbf = [recall_at_k(rec, truth, k=5) for rec, truth in zip(cbf_recommendations, ground_truth)]

# Hitung precision dan recall untuk KNN
precisions_knn = [precision_at_k(rec, truth, k=5) for rec, truth in zip(knn_recommendations, ground_truth)]
recalls_knn = [recall_at_k(rec, truth, k=5) for rec, truth in zip(knn_recommendations, ground_truth)]

print(f"CBF Avg Precision@5: {sum(precisions_cbf)/len(precisions_cbf):.2f}")
print(f"CBF Avg Recall@5: {sum(recalls_cbf)/len(recalls_cbf):.2f}")
print(f"KNN Avg Precision@5: {sum(precisions_knn)/len(precisions_knn):.2f}")
print(f"KNN Avg Recall@5: {sum(recalls_knn)/len(recalls_knn):.2f}")